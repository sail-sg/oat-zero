python training/zero_math.py --critic_type grpo --gpus 8 --vllm_gpu_ratio 0.7 --gradient-checkpointing --flash-attn --bf16 --rnd-seed --learning_rate 0.000001 --lr_scheduler polynomial --kl_penalty_coef 0 --num_ppo_epochs 1 --beta 0.001 --non_stop_penalty 0 --oracle_type reward --oracle gsm8k --pretrain Qwen/Qwen2.5-Math-7B --zero-stage 3 --ref_offload --prompt_data ./data/math_level3to5_8k --train_split train --input_key input --output_key gt_answer --max-train 9999999 --num_prompt_epoch 1 --prompt_max_length 1000 --sync_params_every 1 --num_samples 8 --max_step_adjustment 8 --critic_max_step_adjustment 8 --temperature 0.6 --top_p 0.9 --generate_max_length 1500 --save_steps 4 --train_batch_size 128 --train_batch_size_per_device 1 --mini_train_batch_size_per_device 1 --rollout_batch_size 128 --rollout_batch_size_per_device 32 --pi_buffer_maxlen_per_device 256 --eval_batch_size 200 --eval_steps 4 --eval_temperature 0 --eval_generate_max_length 1500 --eval_split eval --use-wb --wb-run-name qwen-2.5-math-7b-grpo-beta0.001-temp0.6 --wb_project oat-zero --save_path ./output/oat-zero-training
